{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae2cb0e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>qty_dot_url</th>\n",
       "      <th>qty_hyphen_url</th>\n",
       "      <th>qty_underline_url</th>\n",
       "      <th>qty_slash_url</th>\n",
       "      <th>qty_questionmark_url</th>\n",
       "      <th>qty_equal_url</th>\n",
       "      <th>qty_at_url</th>\n",
       "      <th>qty_and_url</th>\n",
       "      <th>qty_exclamation_url</th>\n",
       "      <th>...</th>\n",
       "      <th>qty_ip_resolved</th>\n",
       "      <th>qty_nameservers</th>\n",
       "      <th>qty_mx_servers</th>\n",
       "      <th>ttl_hostname</th>\n",
       "      <th>tls_ssl_certificate</th>\n",
       "      <th>qty_redirects</th>\n",
       "      <th>url_google_index</th>\n",
       "      <th>domain_google_index</th>\n",
       "      <th>url_shortened</th>\n",
       "      <th>phishing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55124</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>43200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44575</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>14399</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>87793</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>292</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5689</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3600</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38932</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>21596</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 113 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  qty_dot_url  qty_hyphen_url  qty_underline_url  qty_slash_url  \\\n",
       "0       55124            2               0                  0              0   \n",
       "1       44575            3               0                  0              0   \n",
       "2       87793            2               0                  0              0   \n",
       "3        5689            2               0                  0              0   \n",
       "4       38932            2               0                  0              0   \n",
       "\n",
       "   qty_questionmark_url  qty_equal_url  qty_at_url  qty_and_url  \\\n",
       "0                     0              0           0            0   \n",
       "1                     0              0           0            0   \n",
       "2                     0              0           0            0   \n",
       "3                     0              0           0            0   \n",
       "4                     0              0           0            0   \n",
       "\n",
       "   qty_exclamation_url  ...  qty_ip_resolved  qty_nameservers  qty_mx_servers  \\\n",
       "0                    0  ...                1                4               5   \n",
       "1                    0  ...                1                2               5   \n",
       "2                    0  ...                1                4               0   \n",
       "3                    0  ...                1                3               1   \n",
       "4                    0  ...                1                2               1   \n",
       "\n",
       "   ttl_hostname  tls_ssl_certificate  qty_redirects  url_google_index  \\\n",
       "0         43200                    0              0                 0   \n",
       "1         14399                    1              1                 0   \n",
       "2           292                    1              0                 0   \n",
       "3          3600                    1              1                 0   \n",
       "4         21596                    1              2                 0   \n",
       "\n",
       "   domain_google_index  url_shortened  phishing  \n",
       "0                    0              0         0  \n",
       "1                    0              0         0  \n",
       "2                    0              0         0  \n",
       "3                    0              0         0  \n",
       "4                    0              0         0  \n",
       "\n",
       "[5 rows x 113 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Carga de Datos ---\n",
    "import pandas as pd\n",
    "df = pd.read_csv('trainData.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c47c4659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Preprocesamiento: Verificar valores nulos y valores negativos ---\n",
    "import numpy as np\n",
    "\n",
    "# Reemplazar valores nulos por 0\n",
    "df = df.fillna(0)\n",
    "\n",
    "# Reemplazar valores negativos por 0 en todas las columnas numéricas\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns\n",
    "df[num_cols] = df[num_cols].clip(lower=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf342d79",
   "metadata": {},
   "source": [
    "## Cálculo de Hiperparámetros Óptimos\n",
    "\n",
    "Para determinar los mejores hiperparámetros de cada modelo, se utilizó validación cruzada estratificada de 10 pliegues (`StratifiedKFold`). Sin embargo, debido al elevado tiempo de ejecución de algunos clasificadores (hasta 50 minutos en ciertos casos), se optó por **comentar el código asociado al ajuste de hiperparámetros** para permitir que el resto del notebook se pueda ejecutar sin interrupciones.\n",
    "\n",
    "En cada bloque comentado se indican explícitamente los **resultados obtenidos** (mejores hiperparámetros y sus F1-Score asociados), los cuales deben ser considerados para construir y entrenar al modelo definitivo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa62e29c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# 10-fold cross-validation\\ncv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)  \\n\\n\\n\\n# Normalización y balanceo dentro de cada fold\\n\\nknn_params = {\\'knn__n_neighbors\\': list(range(1, 21))}\\nknn_pipeline = Pipeline([\\n    (\\'scaler\\', StandardScaler()),\\n    (\\'smote\\', SMOTE(random_state=42)),\\n    (\\'knn\\', KNeighborsClassifier())\\n])\\n\\ngrid_knn = GridSearchCV(knn_pipeline, knn_params, cv=cv, scoring=scoring, n_jobs=-1)\\ngrid_knn.fit(X, y)\\nprint(\"Mejor K para KNN:\", grid_knn.best_params_)\\nprint(\"Mejor F1-Score:\", grid_knn.best_score_)\\n\\n# Esto se demora mucho en ejecutarse.(5min aprox)\\n\\n# --- Resultado obtenido  ---\\n# Mejor K para KNN: {\\'knn__n_neighbors\\': 4} \\n# Mejor F1-Score: 0.9215568833373402\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Modelamiento y Evaluación ---\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, make_scorer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline  \n",
    "\n",
    "# Separar features y target\n",
    "X = df.drop('phishing', axis=1)  \n",
    "y = df['phishing'] \n",
    "\n",
    "# Definir métrica\n",
    "scoring = 'f1'  # Usar F1-Score como métrica de evaluación\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# --- KNN: Búsqueda de hiperparámetro óptimo ---\n",
    "# Este bloque realiza una búsqueda de hiperparámetros para el clasificador K-Nearest Neighbors (KNN) usando GridSearchCV.\n",
    "# Se prueba el número de vecinos (n_neighbors) desde 1 hasta 20, usando validación cruzada estratificada de 10 pliegues.\n",
    "# El pipeline incluye normalización (StandardScaler) y balanceo de clases (SMOTE).\n",
    "# Al final, imprime el mejor valor de K y el mejor F1-Score obtenido.\n",
    "# 10-fold cross-validation\n",
    "\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)  \n",
    "\n",
    "\n",
    "\n",
    "# Normalización y balanceo dentro de cada fold\n",
    "\n",
    "knn_params = {'knn__n_neighbors': list(range(1, 21))}\n",
    "knn_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "grid_knn = GridSearchCV(knn_pipeline, knn_params, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "grid_knn.fit(X, y)\n",
    "print(\"Mejor K para KNN:\", grid_knn.best_params_)\n",
    "print(\"Mejor F1-Score:\", grid_knn.best_score_)\n",
    "\n",
    "# Esto se demora mucho en ejecutarse.(5min aprox)\n",
    "\n",
    "# --- Resultado obtenido  ---\n",
    "# Mejor K para KNN: {'knn__n_neighbors': 4} \n",
    "# Mejor F1-Score: 0.9215568833373402\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6283cde4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n# --- Árbol de Decisión ---\\ntree_params = {\\'tree__max_depth\\': list(range(1, 21))}\\ntree_pipeline = Pipeline([\\n    (\\'scaler\\', StandardScaler()),\\n    (\\'smote\\', SMOTE(random_state=42)),\\n    (\\'tree\\', DecisionTreeClassifier(random_state=42))\\n])\\n\\ngrid_tree = GridSearchCV(tree_pipeline, tree_params, cv=cv, scoring=scoring, n_jobs=-1)\\ngrid_tree.fit(X, y)\\nprint(\"Mejor max_depth para Árbol:\", grid_tree.best_params_)\\nprint(\"Mejor F1-Score:\", grid_tree.best_score_)\\n\\n# --- Resultado obtenido ---\\n#   Mejor max_depth para Árbol: {\\'tree__max_depth\\': 14}\\n#   Mejor F1-Score: 0.935073970535818\\n\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "# --- Árbol de Decisión: Búsqueda de hiperparámetro óptimo ---\n",
    "# Este bloque realiza una búsqueda de hiperparámetros para el clasificador Árbol de Decisión usando GridSearchCV.\n",
    "# Se prueba la profundidad máxima (max_depth) desde 1 hasta 20, usando validación cruzada estratificada de 10 pliegues.\n",
    "# El pipeline incluye normalización (StandardScaler) y balanceo de clases (SMOTE).\n",
    "# Al final, imprime la mejor profundidad y el mejor F1-Score obtenido.\n",
    "\n",
    "\n",
    "tree_params = {'tree__max_depth': list(range(1, 21))}\n",
    "tree_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('tree', DecisionTreeClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "grid_tree = GridSearchCV(tree_pipeline, tree_params, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "grid_tree.fit(X, y)\n",
    "print(\"Mejor max_depth para Árbol:\", grid_tree.best_params_)\n",
    "print(\"Mejor F1-Score:\", grid_tree.best_score_)\n",
    "\n",
    "# --- Resultado obtenido ---\n",
    "#   Mejor max_depth para Árbol: {'tree__max_depth': 14}\n",
    "#   Mejor F1-Score: 0.935073970535818\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5045050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# --- Naive Bayes ---\\nnb_params = {\\'nb__var_smoothing\\': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1]}\\nnb_pipeline = Pipeline([\\n    (\\'scaler\\', StandardScaler()),\\n    (\\'smote\\', SMOTE(random_state=42)),\\n    (\\'nb\\', GaussianNB())\\n])\\n\\ngrid_nb = GridSearchCV(nb_pipeline, nb_params, cv=cv, scoring=scoring, n_jobs=-1)\\ngrid_nb.fit(X, y)\\nprint(\"Mejor var_smoothing para NB:\", grid_nb.best_params_)\\nprint(\"Mejor F1-Score:\", grid_nb.best_score_)\\n\\n# --- Resultado Obtenido ---\\n# Mejor var_smoothing para NB: {\\'nb__var_smoothing\\': 0.01}\\n# Mejor F1-Score: 0.4459903427029562\\n\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# --- Naive Bayes: Búsqueda de hiperparámetro óptimo ---\n",
    "# Este bloque realiza una búsqueda de hiperparámetros para el clasificador Naive Bayes usando GridSearchCV.\n",
    "# Se prueba el parámetro 'var_smoothing' en 10 valores distintos, usando validación cruzada estratificada de 10 pliegues.\n",
    "# El pipeline incluye normalización (StandardScaler) y balanceo de clases (SMOTE).\n",
    "# Al final, imprime el mejor valor de 'var_smoothing' y el mejor F1-Score obtenido.\n",
    "\n",
    "\n",
    "nb_params = {'nb__var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1]}\n",
    "nb_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('nb', GaussianNB())\n",
    "])\n",
    "\n",
    "grid_nb = GridSearchCV(nb_pipeline, nb_params, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "grid_nb.fit(X, y)\n",
    "print(\"Mejor var_smoothing para NB:\", grid_nb.best_params_)\n",
    "print(\"Mejor F1-Score:\", grid_nb.best_score_)\n",
    "\n",
    "# --- Resultado Obtenido ---\n",
    "# Mejor var_smoothing para NB: {'nb__var_smoothing': 0.01}\n",
    "# Mejor F1-Score: 0.4459903427029562\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2cdc3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\\n\\n# --- Regresión Logística: búsqueda del mejor penalty ---\\n\\n\\nlog_params = {\\n    \\'log__penalty\\': [\\'l1\\', \\'l2\\', \\'elasticnet\\'],\\n    \\'log__solver\\': [\\'saga\\'],\\n    \\'log__C\\': [0.01, 0.1, 1, 10],\\n    \\'log__l1_ratio\\': [0.5]  # Solo se usa cuando penalty=\\'elasticnet\\'\\n}\\nlog_pipeline = Pipeline([\\n    (\\'scaler\\', StandardScaler()),\\n    (\\'smote\\', SMOTE(random_state=42)),\\n    (\\'log\\', LogisticRegression(max_iter=1000, random_state=42))\\n])\\n\\ngrid_log = GridSearchCV(log_pipeline, log_params, cv=cv, scoring=scoring, n_jobs=-1, verbose=2)\\ngrid_log.fit(X, y)\\nprint(\"Mejor penalty para Regresión Logística:\", grid_log.best_params_[\\'log__penalty\\'])\\nprint(\"Mejor combinación de hiperparámetros:\", grid_log.best_params_)\\nprint(\"Mejor F1-Score:\", grid_log.best_score_)\\n\\n\\n#   -- Resultados Obtenidos-- (La ejecucion tomo 50min)\\n#   Mejor penalty para Regresión Logística: l1\\n#   Mejor combinación de hiperparámetros: {\\'log__C\\': 1, \\'log__l1_ratio\\': 0.5, \\'log__penalty\\': \\'l1\\', \\'log__solver\\': \\'saga\\'}\\n#   Mejor F1-Score: 0.9040002993680263\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"\n",
    "\n",
    "# --- Regresión Logística: Búsqueda del mejor penalty ---\n",
    "# Este bloque realiza una búsqueda de hiperparámetros para Regresión Logística usando GridSearchCV.\n",
    "# Se prueban distintos valores de penalty ('l1', 'l2', 'elasticnet'), el parámetro de regularización C y l1_ratio (para elasticnet).\n",
    "# Usa validación cruzada estratificada de 10 pliegues, normalización y balanceo de clases.\n",
    "# Al final, imprime la mejor combinación de hiperparámetros y el mejor F1-Score obtenido.\n",
    "\n",
    "\n",
    "\n",
    "log_params = {\n",
    "    'log__penalty': ['l1', 'l2', 'elasticnet'],\n",
    "    'log__solver': ['saga'],\n",
    "    'log__C': [0.01, 0.1, 1, 10],\n",
    "    'log__l1_ratio': [0.5]  # Solo se usa cuando penalty='elasticnet'\n",
    "}\n",
    "log_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('log', LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "grid_log = GridSearchCV(log_pipeline, log_params, cv=cv, scoring=scoring, n_jobs=-1, verbose=2)\n",
    "grid_log.fit(X, y)\n",
    "print(\"Mejor penalty para Regresión Logística:\", grid_log.best_params_['log__penalty'])\n",
    "print(\"Mejor combinación de hiperparámetros:\", grid_log.best_params_)\n",
    "print(\"Mejor F1-Score:\", grid_log.best_score_)\n",
    "\n",
    "\n",
    "#   -- Resultados Obtenidos-- (La ejecucion tomo 50min)\n",
    "#   Mejor penalty para Regresión Logística: l1\n",
    "#   Mejor combinación de hiperparámetros: {'log__C': 1, 'log__l1_ratio': 0.5, 'log__penalty': 'l1', 'log__solver': 'saga'}\n",
    "#   Mejor F1-Score: 0.9040002993680263\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fc47eb",
   "metadata": {},
   "source": [
    "## Selección del Mejor Modelo\n",
    "\n",
    "Luego de comparar los F1-Score obtenidos por cada modelo con sus respectivos hiperparámetros óptimos, se determinó que el **mejor modelo es el Árbol de Decisión**, con una profundidad máxima (`max_depth`) de **14**.\n",
    "\n",
    "Este modelo alcanzó un **F1-Score de 0.935**, superando al resto de los clasificadores evaluados (KNN, Naive Bayes y Regresión Logística). A continuación, se realiza una evaluación adicional del modelo mediante una partición 80/20 del conjunto de entrenamiento, con el objetivo de validar su capacidad de generalización en datos no vistos.\n",
    "\n",
    "Posteriormente, y en base a estos resultados, el modelo se entrena utilizando la totalidad del conjunto `train.csv` y se aplica sobre el conjunto `test.csv` para generar las predicciones finales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e443a421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reporte de clasificación en el set de testeo:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97      9278\n",
      "           1       0.92      0.95      0.94      4906\n",
      "\n",
      "    accuracy                           0.96     14184\n",
      "   macro avg       0.95      0.95      0.95     14184\n",
      "weighted avg       0.96      0.96      0.96     14184\n",
      "\n",
      "Matriz de confusión:\n",
      "[[8883  395]\n",
      " [ 240 4666]]\n"
     ]
    }
   ],
   "source": [
    "mejor_max_depth = 14  # Valor obtenido del GridSearchCV para el árbol de decisión\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separar en entrenamiento y testeo (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Pipeline para determinar desempeño\n",
    "final_tree_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('tree', DecisionTreeClassifier(max_depth=mejor_max_depth, random_state=42))\n",
    "])\n",
    "\n",
    "# Entrenar solo con el set de entrenamiento\n",
    "final_tree_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = final_tree_pipeline.predict(X_test)\n",
    "\n",
    "# Evaluar desempeño\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(\"Reporte de clasificación en el set de testeo:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Matriz de confusión:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df14447",
   "metadata": {},
   "source": [
    "## Evaluación del Modelo en un Subconjunto de Validación\n",
    "\n",
    "El resultado fue el siguiente:\n",
    "\n",
    "- **Accuracy**: 96%\n",
    "- **F1-Score phishing (clase 1)**: 94%\n",
    "\n",
    "\n",
    "- **Matriz de Confusión**:\n",
    "  - Verdaderos Positivos: 4666\n",
    "  - Falsos Positivos: 395\n",
    "  - Falsos Negativos: 240\n",
    "  - Verdaderos Negativos: 8883\n",
    "\n",
    "Esto indica que el modelo generaliza bien y no presenta un sobreajuste evidente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b091a194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Entrenamiento final con Árbol de Decisión y evaluación en set de testeo ---\n",
    "\n",
    "# Pipeline final\n",
    "final_tree_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('tree', DecisionTreeClassifier(max_depth=mejor_max_depth, random_state=42))\n",
    "])\n",
    "\n",
    "# Entrenar solo con el set de entrenamiento completo\n",
    "final_tree_pipeline.fit(X, y)\n",
    "\n",
    "# --- Cargar y predecir el set de testeo oficial ---\n",
    "test_data = pd.read_csv(\"testData.csv\") \n",
    "\n",
    "# Aplicar el modelo entrenado\n",
    "y_pred_test = final_tree_pipeline.predict(test_data)\n",
    "\n",
    "# Guardar predicciones en el formato solicitado\n",
    "pd.DataFrame(y_pred_test).to_csv(\"predicciones.csv\", index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95f2604",
   "metadata": {},
   "source": [
    "## Conclusión\n",
    "\n",
    "A lo largo de este trabajo, se desarrolló un sistema de clasificación de sitios web capaz de detectar páginas de phishing con un alto grado de precisión, utilizando un enfoque supervisado basado en árboles de decisión.\n",
    "\n",
    "Tras explorar y comparar diferentes modelos de clasificación (K-Nearest Neighbors, Árbol de Decisión, Naive Bayes y Regresión Logística), se determinó que el árbol de decisión con una profundidad máxima de 14 entregó el mejor desempeño, alcanzando un F1-score promedio de **0.935** en validación cruzada estratificada de 10 pliegues. Esta métrica fue clave para evaluar el modelo dado el desbalance natural entre clases.\n",
    "\n",
    "Además, al realizar una validación interna separando el set de entrenamiento en 80% entrenamiento y 20% testeo, se comprobó que el modelo mantiene un alto desempeño en datos no vistos, con un **F1-score de 0.94 para la clase phishing** y un accuracy total del 96%. Estos resultados refuerzan la robustez del modelo y su capacidad de generalización.\n",
    "\n",
    "Finalmente, se entrenó el modelo con la totalidad del conjunto `train.csv` y se aplicó sobre `test.csv` para generar las predicciones finales, las cuales podrán ser utilizadas para reforzar la ciberseguridad en la red interna de la UAI.\n",
    "\n",
    "Este trabajo no solo evidencia la efectividad del árbol de decisión en tareas de detección de amenazas digitales, sino que también ilustra la importancia de una correcta validación, normalización y balanceo de datos en problemas reales de clasificación."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
